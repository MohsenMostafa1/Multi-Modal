# -*- coding: utf-8 -*-
"""Video-To-Text.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KF4CvnXCL-nphWIRgX44fbLymV6Dlvbu
"""

from google.colab import drive
drive.mount('/content/drive')

# Step 1: Install Required Packages (Run once per session)
!pip install transformers torchaudio pydub ffmpeg-python
!apt-get install -y ffmpeg

# Step 2: Import Libraries
from transformers import AutoModelForSpeechSeq2Seq, AutoTokenizer, pipeline
import torch
from pydub import AudioSegment
from pydub.utils import mediainfo
import os

# Step 3: Extract Audio from Video
def extract_audio_from_video(video_path, audio_output_path):
    # Load video and extract audio
    audio = AudioSegment.from_file(video_path, format="mp4")
    # Export as WAV (required for Whisper)
    audio.export(audio_output_path, format="wav")
    print(f"‚úÖ Audio extracted to {audio_output_path}")

# Step 4: Transcribe Audio using Whisper (with long-form fix)
def transcribe_audio_with_whisper(audio_path):
    # Load pre-trained Whisper model and tokenizer
    model_name = "openai/whisper-base"  # Supports long audio with timestamps
    model = AutoModelForSpeechSeq2Seq.from_pretrained(model_name)
    tokenizer = AutoTokenizer.from_pretrained(model_name)

    # Set up pipeline
    device = "cuda" if torch.cuda.is_available() else "cpu"
    pipe = pipeline(
        task="automatic-speech-recognition",
        model=model,
        tokenizer=tokenizer,
        feature_extractor="openai/whisper-base",
        device=0 if device == "cuda" else -1,
        generate_kwargs={"return_timestamps": True},  # üîë Required for long audio
    )

    # Transcribe
    result = pipe(audio_path)
    print("üìù Transcription:")
    print(result["text"])
    return result["text"]

# Step 5: Full Workflow
def video_to_text(video_path):
    audio_path = "extracted_audio.wav"
    extract_audio_from_video(video_path, audio_path)
    transcription = transcribe_audio_with_whisper(audio_path)

    # Optional: Clean up audio file
    os.remove(audio_path)
    return transcription

# Step 6: Run the Pipeline
if __name__ == "__main__":
    # üìÅ Update this path to your video file
    video_file = "/content/sample_data/videoplayback.mp4"  # Replace with your actual path

    # üß™ Optional: Check if file exists
    if os.path.exists(video_file):
        final_text = video_to_text(video_file)
        print("\nüéâ Final Transcription:\n", final_text)
    else:
        print("‚ùå File NOT found. Check the path:", video_file)



"""# New Section"""

